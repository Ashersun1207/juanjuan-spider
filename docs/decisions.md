# web-scraper — 决策记录

---

## 核心原则

**不造轮子。找最成熟可靠的开源项目集成，在上面做适配和优化。**

- 选项目标准：GitHub 10K+ ⭐、活跃维护、社区大
- 我们只做：选型、封装 CLI、场景适配、输出优化
- 我们不做：重新实现浏览器引擎、反检测算法、内容提取器

---

## D1: 定位为通用爬虫工具（2026-02-26）

**背景**：讨论 web-scraper 的定位
**决策**：通用工具，不局限于金融场景，覆盖所有需要浏览器渲染+反检测的抓取需求
**理由**：
- 爬虫能力是通用的，金融只是使用场景之一
- 新闻、论坛、产品页、文档站、研报都会用到
- 保持通用性，未来可独立发展或集成到任何项目
**影响**：架构设计不针对特定领域，站点适配器作为可插拔模块

## D2: 独立仓库 + Python 技术栈（2026-02-26）

**背景**：放 gainlab-mcp 里还是独立仓库？Python 还是改写 TS？
**决策**：独立仓库 `web-scraper/`，保持 Python
**理由**：
- Playwright Python 生态比 Node 成熟（stealth 库、readability 等）
- 独立仓库方便单独维护和升级依赖
- gainlab-mcp 那边加 tool 代理调用即可
**影响**：技术栈不统一（Python vs TS），但利大于弊

## D3: Readability 作为默认正文提取（2026-02-25）

**背景**：v0.1 内容提取靠启发式去 nav/header/footer，效果一般
**决策**：引入 readability-lxml（Mozilla Readability Python 移植），作为默认提取方式
**理由**：
- Firefox 阅读模式验证过的算法，成熟可靠
- 自动去广告/导航/侧边栏，输出干净正文
- `--raw` 可跳过，保留灵活性
**影响**：新增依赖 readability-lxml，输出质量显著提升

## D4: 代理策略 — 默认走 Clash（2026-02-25）

**背景**：很多目标站点需要代理才能访问
**决策**：默认走本机 Clash（127.0.0.1:7897），`--no-proxy` 可关
**理由**：本机 Clash 稳定可用，不需要额外代理服务
**影响**：国内站点记得加 --no-proxy

## D5: 底层切换到 Crawl4AI（2026-02-26）

**背景**：自写的 Playwright+Stealth+Readability 在 HN/SPA/金十等站点效果差
**决策**：用 Crawl4AI（58K+ ⭐）替代自写引擎，scrape.py 变成薄封装
**理由**：
- 不造轮子，集成成熟项目再优化
- Crawl4AI 原生支持：异步、fit markdown（智能去噪）、反检测、深度爬取
- HN 从空→有内容，金十从只有标题→14K chars
- 社区活跃（50K+），持续维护
**影响**：需要 Python 3.12+（用 venv 隔离），依赖变多但功能大幅增强

## D6: Python 3.12 venv 隔离（2026-02-26）

**背景**：系统 Python 3.9，Crawl4AI 需要 3.10+
**决策**：在项目内用 `python3.12 -m venv .venv`，不动系统 Python
**理由**：隔离干净，不影响其他工具
**影响**：运行需先 `source .venv/bin/activate`

---

_Last updated: 2026-02-26_
