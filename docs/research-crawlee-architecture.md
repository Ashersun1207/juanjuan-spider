# Crawlee Python æ¶æ„åˆ†æ â€” juanjuan-spider å‚è€ƒ

_åŸºäº Crawlee Python v0.6.x æºç ï¼ˆ26590 è¡Œ / 175 æ–‡ä»¶ï¼‰ï¼Œ2026-02-25 æœ€æ–° commitã€‚_

---

## ä¸€ã€Crawlee å®é™…åˆ†å±‚

è¯»å®Œæºç åï¼ŒCrawlee çš„æ¶æ„ä¸æ˜¯"å››å±‚"é‚£ä¹ˆç®€å•ã€‚å®ƒæ˜¯**ä¸€ä¸ªæ ¸å¿ƒ + å…­ä¸ªå¯æ’æ‹”æ¨¡å—**ï¼š

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  BasicCrawler â”‚  â† æ ¸å¿ƒï¼šè¯·æ±‚è°ƒåº¦ + ç”Ÿå‘½å‘¨æœŸç®¡ç†
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                  â”‚                  â”‚
  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
  â”‚  Router    â”‚   â”‚ SessionPool   â”‚   â”‚  Proxy      â”‚
  â”‚ (labelâ†’    â”‚   â”‚ (ä¼šè¯è½®æ¢+    â”‚   â”‚  Configurationâ”‚
  â”‚  handler)  â”‚   â”‚  æŒä¹…åŒ–)      â”‚   â”‚  (ä»£ç†è½®æ¢)  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                  â”‚                  â”‚
  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
  â”‚ Storage    â”‚   â”‚ BrowserPool   â”‚   â”‚ HttpClient  â”‚
  â”‚ Clients    â”‚   â”‚ (æµè§ˆå™¨å®ä¾‹   â”‚   â”‚ (HTTPè¯·æ±‚)  â”‚
  â”‚ (å­˜å‚¨æŠ½è±¡) â”‚   â”‚  ç®¡ç†)        â”‚   â”‚             â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### å…³é”®è®¾è®¡å‘ç°

**1. BasicCrawler æ˜¯å”¯ä¸€çš„"ä¸Šå¸ç±»"ï¼ˆ1678 è¡Œï¼‰**
- ç®¡æ‰€æœ‰äº‹ï¼šè¯·æ±‚è°ƒåº¦ã€é‡è¯•ã€å¹¶å‘æ§åˆ¶ã€Session è½®æ¢ã€ç»Ÿè®¡ã€æŒä¹…åŒ–
- å­ç±»ï¼ˆHttpCrawler / PlaywrightCrawlerï¼‰åªè¦†ç›–"æ€ä¹ˆå‘è¯·æ±‚"å’Œ"æ€ä¹ˆè§£æ"
- **å¯ç¤º**ï¼šæ ¸å¿ƒæ§åˆ¶å™¨å¿…é¡»æ˜¯ä¸€ä¸ªï¼Œä¸è¦åˆ†æ•£

**2. Router æå…¶ç®€å•ï¼ˆ111 è¡Œï¼‰**
- ä¸æ˜¯ URLâ†’å¼•æ“ çš„è·¯ç”±ï¼Œè€Œæ˜¯ **labelâ†’handler** çš„åˆ†å‘
- Request è‡ªå¸¦ label å­—æ®µï¼Œç”¨æˆ·æ‰‹åŠ¨æ ‡è®°
- **å¯ç¤º**ï¼šCrawlee çš„ Router è·Ÿæˆ‘ä»¬æƒ³çš„"URL è·¯ç”±åˆ°ä¸åŒå¼•æ“"å®Œå…¨ä¸åŒ

**3. SessionPool æ˜¯æ ¸å¿ƒç«äº‰åŠ›ï¼ˆ253 è¡Œï¼‰**
- ç»´æŠ¤ Session æ± ï¼ˆé»˜è®¤ 1000 ä¸ªï¼‰ï¼Œéšæœºåˆ†é…
- é€€å½¹æœºåˆ¶ï¼šç”¨æ»¡æ¬¡æ•°/è¿‡æœŸè‡ªåŠ¨æ·˜æ±°
- å¯æŒä¹…åŒ–åˆ° KVSï¼Œé‡å¯åæ¢å¤
- **å¯ç¤º**ï¼šè¿™æ˜¯ç”Ÿäº§çº§çˆ¬è™«å¿…é¡»æœ‰çš„ï¼Œä½† 1000 ä¸ª Session æ˜¯å¤§è§„æ¨¡åœºæ™¯ï¼Œæˆ‘ä»¬ä¸éœ€è¦

**4. ProxyConfiguration æ”¯æŒåˆ†å±‚ä»£ç†ï¼ˆ268 è¡Œï¼‰**
- ä¸‰ç§æ¨¡å¼ï¼šURLåˆ—è¡¨è½®æ¢ / è‡ªå®šä¹‰å‡½æ•° / åˆ†å±‚ä»£ç†
- åˆ†å±‚ä»£ç†æœ€æœ‰æ„æ€ï¼šæŒ‰åŸŸåè‡ªåŠ¨å‡é™çº§ï¼ˆä¾¿å®œä»£ç†å…ˆè¯•ï¼Œè¢«å°äº†è‡ªåŠ¨åˆ‡è´µçš„ï¼‰
- **å¯ç¤º**ï¼šåˆ†å±‚ä»£ç†æ€è·¯å¥½ï¼Œä½†æˆ‘ä»¬ç›®å‰å°±ä¸€ä¸ª Clashï¼Œè¿‡æ—©å¼•å…¥æ²¡æ„ä¹‰

**5. StorageClient æ˜¯ä¸‰çº§æŠ½è±¡ï¼ˆæŠ½è±¡åŸºç±»â†’4ç§å®ç°ï¼‰**
- åŸºç±»å®šä¹‰ Dataset / KVS / RequestQueue ä¸‰ç§å­˜å‚¨
- å®ç°ï¼šMemory / FileSystem / SQL / Redis
- **å¯ç¤º**ï¼šè¿‡åº¦è®¾è®¡ã€‚æˆ‘ä»¬åªéœ€è¦ä¸€ä¸ª SQLite ç¼“å­˜å°±å¤Ÿäº†

**6. æ²¡æœ‰ MCP æ”¯æŒ**
- Crawlee æœ¬èº«æ²¡æœ‰ MCP
- ç¤¾åŒºæœ‰ Apify çš„ MCP actorï¼Œä½†æ˜¯ TypeScript ç‰ˆ
- Python ç‰ˆ MCP éœ€è¦è‡ªå·±å†™

---

## äºŒã€å“ªäº›è¯¥å­¦ã€å“ªäº›ä¸éœ€è¦

| Crawlee èƒ½åŠ› | æ˜¯å¦å€Ÿé‰´ | ç†ç”± |
|---|---|---|
| **BasicCrawler å•ä¸€æ§åˆ¶å™¨æ¨¡å¼** | âœ… å­¦ | ä¸€ä¸ªæ ¸å¿ƒç±»ç®¡è°ƒåº¦ï¼Œå­ç±»åªç®¡"æ€ä¹ˆæŠ“" |
| **Request æ•°æ®æ¨¡å‹** | âœ… å­¦ | url + label + state + retries + userDataï¼Œæ¸…æ™° |
| **é‡è¯• + é”™è¯¯åˆ†ç±»** | âœ… å­¦ | åŒºåˆ† client error / server error / blockedï¼Œä¸åŒç­–ç•¥ |
| **Router label åˆ†å‘** | âš ï¸ æ”¹é€  | æˆ‘ä»¬éœ€è¦ URLâ†’å¼•æ“+é€‚é…å™¨ï¼Œä¸æ˜¯ labelâ†’handler |
| **SessionPool** | âš ï¸ ç®€åŒ– | åªéœ€è¦ç™»å½•æ€ä¿å­˜+å¤ç”¨ï¼Œä¸éœ€è¦ 1000 ä¸ª Session |
| **ProxyConfiguration** | âš ï¸ ç®€åŒ– | åªéœ€è¦å•ä»£ç†+fallbackï¼Œä¸éœ€è¦åˆ†å±‚ä»£ç† |
| **AutoscaledPool** | âŒ ä¸éœ€è¦ | è‡ªåŠ¨æ‰©ç¼©å®¹æ˜¯å¤§è§„æ¨¡åœºæ™¯ï¼Œæˆ‘ä»¬ä¸éœ€è¦ |
| **StorageClient å››ç§å®ç°** | âŒ ä¸éœ€è¦ | SQLite ä¸€ç§å°±å¤Ÿ |
| **Statistics / Events** | âŒ ä¸éœ€è¦ | è¿‡åº¦è®¾è®¡ |
| **fingerprint_suite** | âš ï¸ åæœŸ | Crawl4AI çš„ stealth å·²ç»å¤Ÿç”¨ |

---

## ä¸‰ã€å¯¹ juanjuan-spider çš„æ¶æ„å»ºè®®

åŸºäº Crawlee æºç åˆ†æï¼Œä¿®æ­£ä¹‹å‰çš„å››å±‚è®¾è®¡ï¼š

### æ ¸å¿ƒåŸåˆ™

1. **å•ä¸€æ§åˆ¶å™¨** â€” ä¸€ä¸ª Spider ç±»ç®¡è°ƒåº¦ï¼Œä¸è¦åˆ†æ•£
2. **å¼•æ“å¯æ’æ‹”** â€” ä½†ç°é˜¶æ®µåªæœ‰ Crawl4AI ä¸€ä¸ªï¼Œä¸è¦è¿‡åº¦æŠ½è±¡
3. **é€‚é…å™¨æ˜¯é…ç½®ä¸æ˜¯ä»£ç ** â€” å¤§éƒ¨åˆ†ç«™ç‚¹åªéœ€è¦ YAML é…ç½®ï¼Œä¸éœ€è¦ Python æ–‡ä»¶
4. **MCP æ˜¯æ¥å…¥æ–¹å¼ï¼Œä¸æ˜¯æ¶æ„å±‚** â€” MCP Server åªæ˜¯ Spider çš„ä¸€ä¸ªè°ƒç”¨å…¥å£

### æ¨èæ¶æ„

```
juanjuan-spider/
â”œâ”€â”€ scrape.py              # CLI å…¥å£ï¼ˆè–„å°è£…ï¼‰
â”œâ”€â”€ server.py              # MCP Server å…¥å£ï¼ˆè–„å°è£…ï¼‰
â”‚
â”œâ”€â”€ spider/                # æ ¸å¿ƒåŒ…
â”‚   â”œâ”€â”€ __init__.py        # from spider import Spider
â”‚   â”œâ”€â”€ spider.py          # ğŸ”´ æ ¸å¿ƒæ§åˆ¶å™¨ï¼ˆè°ƒåº¦+é‡è¯•+è·¯ç”±ï¼‰
â”‚   â”œâ”€â”€ request.py         # Request æ•°æ®æ¨¡å‹
â”‚   â”œâ”€â”€ result.py          # CrawlResult æ•°æ®æ¨¡å‹
â”‚   â”œâ”€â”€ config.py          # é…ç½®ç®¡ç†ï¼ˆYAML + envï¼‰
â”‚   â”‚
â”‚   â”œâ”€â”€ engines/           # å¼•æ“ï¼ˆæ€ä¹ˆæŠ“ï¼‰
â”‚   â”‚   â”œâ”€â”€ base.py        # BaseEngine æ¥å£
â”‚   â”‚   â””â”€â”€ crawl4ai.py    # Crawl4AI å¼•æ“ï¼ˆç°é˜¶æ®µå”¯ä¸€ï¼‰
â”‚   â”‚
â”‚   â”œâ”€â”€ adapters/          # ç«™ç‚¹é€‚é…ï¼ˆYAML ä¸ºä¸»ï¼Œå¤æ‚ç«™ç‚¹æ‰å†™ Pythonï¼‰
â”‚   â”‚   â”œâ”€â”€ registry.py    # é€‚é…å™¨æ³¨å†Œè¡¨
â”‚   â”‚   â””â”€â”€ builtin/       # å†…ç½®é€‚é…å™¨
â”‚   â”‚       â”œâ”€â”€ default.yaml
â”‚   â”‚       â”œâ”€â”€ zhihu.yaml
â”‚   â”‚       â”œâ”€â”€ xhs.yaml
â”‚   â”‚       â””â”€â”€ reddit.py  # éœ€è¦ç™»å½•æ€çš„ï¼Œç”¨ Python
â”‚   â”‚
â”‚   â”œâ”€â”€ session.py         # ç™»å½•æ€ç®¡ç†ï¼ˆç®€åŒ–ç‰ˆ SessionPoolï¼‰
â”‚   â”œâ”€â”€ cache.py           # ç»“æœç¼“å­˜ï¼ˆSQLiteï¼‰
â”‚   â””â”€â”€ errors.py          # é”™è¯¯ç±»å‹å®šä¹‰
â”‚
â”œâ”€â”€ mcp/                   # MCP Server
â”‚   â”œâ”€â”€ server.py
â”‚   â””â”€â”€ tools.py           # 5 ä¸ª MCP tools
â”‚
â”œâ”€â”€ adapters/              # ç”¨æˆ·è‡ªå®šä¹‰é€‚é…å™¨ç›®å½•
â”‚   â””â”€â”€ my_site.yaml
â”‚
â”œâ”€â”€ config.yaml            # å…¨å±€é…ç½®
â”œâ”€â”€ docs/
â”œâ”€â”€ scripts/
â””â”€â”€ tests/
```

### å…³é”®è®¾è®¡

**Spiderï¼ˆæ ¸å¿ƒæ§åˆ¶å™¨ï¼‰â€” å­¦ BasicCrawler çš„å•ä¸€èŒè´£ï¼š**
```python
class Spider:
    """juanjuan-spider æ ¸å¿ƒæ§åˆ¶å™¨"""
    
    async def crawl(self, url, **options) -> CrawlResult:
        """æŠ“å–å•ä¸ª URL â€” æ ¸å¿ƒæ–¹æ³•"""
        adapter = self.router.match(url)          # 1. åŒ¹é…é€‚é…å™¨
        config = adapter.merge(options)            # 2. åˆå¹¶é…ç½®
        engine = self.get_engine(adapter.engine)   # 3. è·å–å¼•æ“
        
        for attempt in range(self.max_retries):    # 4. é‡è¯•å¾ªç¯
            try:
                raw = await engine.fetch(url, config)
                return adapter.transform(raw)      # 5. é€‚é…å™¨è½¬æ¢
            except BlockedError:
                await self.rotate_session()        # 6. è¢«å°â†’æ¢Session
            except Exception as e:
                if attempt == self.max_retries - 1:
                    raise
    
    async def batch(self, urls, **options) -> list[CrawlResult]:
        """æ‰¹é‡æŠ“å–"""
    
    async def deep_crawl(self, url, max_depth, **options):
        """æ·±åº¦çˆ¬å–"""
```

**é€‚é…å™¨ä»¥ YAML ä¸ºä¸»ï¼š**
```yaml
# adapters/builtin/zhihu.yaml
name: zhihu
domains:
  - zhihu.com
  - zhuanlan.zhihu.com
engine: crawl4ai
scroll: true
wait_for: ".ContentItem"
css_selector: ".RichContent-inner"
format: fit
```

**åªæœ‰éœ€è¦ç™»å½•æ€/JS ç­¾åçš„ç«™ç‚¹æ‰å†™ Python é€‚é…å™¨ã€‚**

### MCP Toolsï¼ˆ5ä¸ªï¼‰

```yaml
spider_scrape:     # æŠ“å–å•ä¸ª URL
spider_screenshot: # ç½‘é¡µæˆªå›¾  
spider_search:     # å¹³å°å†…æœç´¢
spider_batch:      # æ‰¹é‡æŠ“å–
spider_deep_crawl: # æ·±åº¦çˆ¬å–
```

---

## å››ã€ä¸ä¹‹å‰æ¶æ„çš„å·®å¼‚

| ä¹‹å‰çš„è®¾è®¡ | ä¿®æ­£å | ç†ç”± |
|---|---|---|
| å››å±‚åˆ†ç¦» | æ ¸å¿ƒæ§åˆ¶å™¨ + å¯æ’æ‹”æ¨¡å— | Crawlee è¯æ˜å•ä¸€æ§åˆ¶å™¨æ›´æ¸…æ™° |
| æ¯ä¸ªç«™ç‚¹ä¸€ä¸ª .py | YAML ä¸ºä¸»ï¼Œ.py ä¸ºè¾… | å¤§éƒ¨åˆ†é€‚é…åªæ˜¯é…ç½®å·®å¼‚ |
| Router ç‹¬ç«‹å±‚ | Router æ˜¯ Spider å†…éƒ¨æ–¹æ³• | è·¯ç”±é€»è¾‘ç®€å•ï¼Œä¸éœ€è¦ç‹¬ç«‹å±‚ |
| ProxyManager ç‹¬ç«‹æ¨¡å— | config.yaml é‡Œé… | ç°é˜¶æ®µä¸éœ€è¦å¤æ‚ä»£ç†ç®¡ç† |
| Output ç‹¬ç«‹å±‚ | CrawlResult è‡ªå¸¦å¤šæ ¼å¼ | è¾“å‡ºæ ¼å¼è½¬æ¢å¾ˆè½»ï¼Œä¸å€¼å¾—æŠ½å±‚ |

---

_Last updated: 2026-02-26_
